{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> KIT Praktikum NN: L2-regularized Logistic Least Squares Regression </center>\n",
    "\n",
    "</br>\n",
    "On this exercise, you are going to apply what you learn from the `numpy` tutorial in the implementation of L2-regularized Logistic Least Squares Regression (LLSR). I will provide you the formula by now (you can do it yourself after the next lecture!!!), first you should use pens and papers to vectorize them. Then you implement the full of the classifier based on your vectorized version.\n",
    "\n",
    "<img src=\"../Images/LogisticRegression.png\" style=\"width:298px;height:275px\">\n",
    "\n",
    "</br>\n",
    "L2-regularized Logistic Least Squares Regression is similar to the standard Logistic Regression: It is a binary classifier containing only one layer, mapping the input features to only one output using sigmoid function. The differents here are two things: \n",
    "* Instead of the _binary crossentropy error_ for the loss, it uses the _squared error_.\n",
    "* It is applied the L2-regularization.\n",
    "\n",
    "Note that we will do an SGD training for this exercise. More specifically:\n",
    "* There are $m$ data instance on the training set, each has $n$ input features. \n",
    "* $x_{i}^{(j)}$ denotes the $i^{th}$ input feature of the $j^{th}$ data instance.\n",
    "* $y^{(j)}$ denotes the binary label ($0$ or $1$) of the $j^{th}$ data instance.\n",
    "* $w_{i}$ denotes the weight connecting the $i^{th}$ input feature to the output.\n",
    "* $b$ is the bias of the Logistic Least Squares Regression.\n",
    "\n",
    "So the steps of an unvectorized version are:\n",
    "* The weights are initialized using Xavier Initialization, the bias can be initialized as 0.\n",
    "* Train over 5 epochs, each epoch we do those steps:\n",
    "  *  Loop over every data instance $x^{(j)}$:\n",
    "     * Calculate the output of the LLSR: $o^{(j)} = \\sigma(\\sum_{i=1}^{n} w_ix_i^{(j)} + b)$\n",
    "     * Calculate the cost: squared error $c^{(j)} = (y^{(j)} - o^{(j)})^2$\n",
    "     * The final loss function is L2-regularized: $l^{(j)} = \\frac{1}{2}c^{(j)} + \\frac{\\lambda}{2}\\sum_{i=1}^{n}w_i^2$. \n",
    "     * Update the weights: \n",
    "         * Loop over every weight $w_i$ and update once at a time: $w_i = w_i - \\eta((o^{(j)}-y^{(j)})o^{(j)}(1-o^{(j)})x_i^{(j)} + \\lambda w_i)$\n",
    "     * Update the bias: $b = b - \\eta (o^{(j)}-y^{(j)})o^{(j)}(1-o^{(j)})$\n",
    "  *  Calculate the total loss (of the epoch): $L = \\frac{1}{m}\\sum_{j=1}^{m}l^{(j)}$. Print it out. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The guideline is to avoid explicit for-loops. _Hint_: We cannot make the epoch loop disappears, but all other loops can be replaced by vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import numpy and math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will use LLSR for the MNIST_SEVEN task: predict a $128\\times 128$-pixel image of a handwritten digit whether it is a \"7\" or not. This is a binary classification task. I did the data reading for you. There is 5000 images, I split the first 4000 images for training, 500 images for tuning, 500 images for test. On this exercise we do not need to tune anything, so we'd leave the tuning (called the _dev set_) untouch. The first field is the label (\"0\"-\"9\") of the image, the rest are the grayscale value of each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/mnist_seven.csv\"\n",
    "data = np.genfromtxt(data_path, delimiter=\",\", dtype=\"uint8\")\n",
    "train, dev, test = data[:4000], data[4000:4500], data[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    X = dataset[:, 1:] / 255.     # Normalize input features\n",
    "    Y = (dataset[:, 0] == 7) * 1  # Convert labels from 0-9 to Is7 (1) or IsNot7(0)\n",
    "    return X.T,Y.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 4000)\n",
      "(1, 4000)\n",
      "(784, 500)\n",
      "(1, 500)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = normalize(train)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "X_test, Y_test = normalize(test)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "# shuffle the training data since we do SGD\n",
    "# we shuffle outside the training \n",
    "# since we want to compare unvectorized and vectorized versions\n",
    "# It doesn't affect to batch training later\n",
    "np.random.seed(8888)     # Do not change those seedings to make our results comparable\n",
    "np.random.shuffle(train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unvectorized Version of Stochastic Gradient Descent\n",
    "\n",
    "First the unvectorized version of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unvectorized(X_train, Y_train, lr=0.2, lambdar=0.0001, epochs=5):\n",
    "    \n",
    "    n = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "    \n",
    "    # Xavier Initialization\n",
    "    np.random.seed(1234)\n",
    "    w = np.random.randn(n) * (np.sqrt(2. / (n + 1)))\n",
    "    b = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        L = 0\n",
    "        for j in range(m):   # Loop over every training instance\n",
    "            # Forward pass\n",
    "            # CODE HERE\n",
    "            out = b\n",
    "            \n",
    "            for i in range(len(w)):\n",
    "                out += w[i]*X_train[i,j]\n",
    "            \n",
    "            o = 1/(1 + np.exp(-out))\n",
    "\n",
    "            # Calculate the loss\n",
    "            # CODE HERE\n",
    "            L += (Y_train[0,j] - o)**2\n",
    "            \n",
    "            # Backward pass and update the weights/bias\n",
    "            # CODE HERE\n",
    "            for i in range(len(w)):\n",
    "                w[i] -= lr*((o - Y_train[0,j])*o*(1 - o)*X_train[i,j] + lambdar*w[i])\n",
    "                \n",
    "            b -= lr*((o - Y_train[0,j])*o*(1 - o))\n",
    "        \n",
    "        # Accumulate the total loss and print it\n",
    "        L /= m\n",
    "        print(\"Error of the epoch {0}: {1}\".format(epoch + 1, L))\n",
    "    \n",
    "    return w, b\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the (unvectorized) inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unvectorized(X_test, Y_test, w, b):\n",
    "    \n",
    "    n_test = X_test.shape[0]\n",
    "    m_test = X_test.shape[1]\n",
    "    corrects = 0\n",
    "    \n",
    "    for j in range(m_test):\n",
    "        \n",
    "        # Forward pass\n",
    "        # CODE HERE\n",
    "        out = b\n",
    "            \n",
    "        for i in range(len(w)):\n",
    "            out += w[i]*X_test[i,j]\n",
    "\n",
    "        o = 1/(1 + np.exp(-out))\n",
    "        \n",
    "        # Evaluate the outputs\n",
    "        # CODE HERE\n",
    "        if np.rint(o) == Y_test[0,j]:\n",
    "            corrects += 1\n",
    "        \n",
    "        \n",
    "    print(\"Accuracy of our LLSR:\" + str((corrects * 100.) / m_test) + \"%\")\n",
    "    \n",
    "    return corrects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on our test data. The accuracy should be better than 89.2%. This high score 89.2% is the baseline, achieved by do nothing rather than predicting all images are not a \"seven\" :p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of the epoch 1: 0.02227099791815772\n",
      "Error of the epoch 2: 0.015494194498583323\n",
      "Error of the epoch 3: 0.013894081012307198\n",
      "Error of the epoch 4: 0.012974585494809749\n",
      "Error of the epoch 5: 0.012167139245510663\n",
      "Accuracy of our LLSR:98.4%\n"
     ]
    }
   ],
   "source": [
    "w, b = train_unvectorized(X_train, Y_train)\n",
    "_ = test_unvectorized(X_test, Y_test, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Version of Stochastic Gradient Descent\n",
    "\n",
    "Now we move to the vectorized version of training and inference, just replace for-loops and total-sums by $np.dot()$,  $np.sum()$ and the numpy pair-wise operations (you should do the vectorization using pens and papers first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vectorized(X_train, Y_train, lr=0.2, lambdar=0.0001, epochs=5):\n",
    "    \n",
    "    n = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "    \n",
    "    # Xavier Initialization\n",
    "    np.random.seed(1234)\n",
    "    w = np.random.randn(n) * (np.sqrt(2. / (n + 1)))\n",
    "    b = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        L = 0\n",
    "        for j in range(m):\n",
    "\n",
    "            # Forward pass\n",
    "            # CODE HERE\n",
    "            out = b            \n",
    "            out += np.dot(w, X_train[:,j])            \n",
    "            o = 1/(1 + np.exp(-out))            \n",
    "            \n",
    "            # Calculate the loss (for each instance - SGD) \n",
    "            # CODE HERE\n",
    "            L += (Y_train[0,j] - o)**2\n",
    "            \n",
    "            # Backward pass and update the weights/bias (for each instance - SGD) \n",
    "            # CODE HERE\n",
    "            w -= lr*((o - Y_train[0,j])*o*(1 - o)*X_train[:,j] + lambdar*w)                \n",
    "            b -= lr*((o - Y_train[0,j])*o*(1 - o))\n",
    "            \n",
    "        L /= m\n",
    "        print(\"Error of the epoch {0}: {1}\".format(epoch + 1, L))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the vectorized inference (short, clear and fast):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vectorized(X_test, Y_test, w, b):\n",
    "    \n",
    "    m_test = X_test.shape[1]\n",
    "    \n",
    "    \n",
    "    out = b\n",
    "    out += np.dot(w, X_test)\n",
    "    \n",
    "    o = 1/(1 + np.exp(-out))\n",
    "    \n",
    "    corrects = np.sum(np.rint(o) == Y_test)\n",
    "    \n",
    "    print(\"Accuracy of our LLSR:\" + str((corrects * 100.) / m_test) + \"%\")\n",
    "    \n",
    "    return corrects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those following runs should return exact the same outputs like the (unvectorized) training and inference before but in less than a second. The vectorization should be more effective (much faster) if this is not an one-layer logistic regression but a deep network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of the epoch 1: 0.022270997918157717\n",
      "Error of the epoch 2: 0.015494194498583325\n",
      "Error of the epoch 3: 0.013894081012307201\n",
      "Error of the epoch 4: 0.012974585494809752\n",
      "Error of the epoch 5: 0.012167139245510668\n",
      "Accuracy of our LLSR:98.4%\n"
     ]
    }
   ],
   "source": [
    "w, b = train_vectorized(X_train, Y_train)\n",
    "_ = test_vectorized(X_test, Y_test, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Version of Batch Gradient Descent \n",
    "\n",
    "Here is the fully vectorized version, batch training (vectorizing over training instances). The formula (you might be able to derive them after the next lecture):\n",
    "\n",
    "$$ z = w \\cdot X + b $$\n",
    "\n",
    "$$ o = \\sigma(z) $$\n",
    "\n",
    "$$ C = \\frac{1}{2m}\\sum_{j=1}^{m}(y^{(j)}-o^{(j)})^2 $$\n",
    "\n",
    "$$ R = \\frac{1}{2m}\\sum_{i=1}^{n}w_i^2 $$\n",
    "\n",
    "$$ L = C + \\lambda R $$\n",
    "\n",
    "$$ \\frac{\\partial C}{\\partial z^{(j)}} = \\frac{1}{m}(o^{(j)} - Y^{(j)}) * o^{(j)} * (1 - o^{(j)}) $$\n",
    "\n",
    "$$ \\frac{\\partial z^{(j)}}{\\partial w_i} = x_i $$\n",
    "\n",
    "$$ \\Rightarrow \\frac{\\partial C}{\\partial w} = \\frac{\\partial C}{\\partial z} \\cdot X^T $$\n",
    "\n",
    "$$ \\frac{\\partial R}{\\partial w} = \\frac{1}{m}w $$ \n",
    "\n",
    "$$ \\Rightarrow \\frac{\\partial L}{\\partial w} = \\frac{\\partial C}{\\partial w} + \\lambda\\frac{\\partial R}{\\partial w} $$\n",
    "\n",
    "$$ \\frac{\\partial z}{\\partial b} = 1 $$\n",
    "\n",
    "$$ \\Rightarrow \\frac{\\partial L}{\\partial b} = \\frac{\\partial C}{\\partial b} = \\frac{1}{m} \\sum_{j=1}^{m}(o^{(j)} - Y^{(j)}) * o^{(j)} * (1 - o^{(j)}) $$\n",
    "\n",
    "$$ w = w - \\eta * \\frac{\\partial L}{\\partial w} $$\n",
    "\n",
    "$$ b = b - \\eta *  \\frac{\\partial L}{\\partial b} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(X_train, Y_train, lr=0.1, lambdar=0.0001, epochs=50):\n",
    "    \n",
    "    n = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "\n",
    "    # Xavier Initialization\n",
    "    np.random.seed(1234)\n",
    "    w = np.random.randn(1, n) * (np.sqrt(2. / (n + 1)))\n",
    "    b = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Forward pass\n",
    "        # CODE HERE\n",
    "        z = b\n",
    "            \n",
    "        #for i in range(len(w)):\n",
    "            #out += w[i]*X_train[i,j]\n",
    "        z += np.dot(w, X_train)\n",
    "\n",
    "        o = 1.0/(1.0 + np.exp(-z))\n",
    "        #o = np.exp(z) / (1+np.exp(z))\n",
    "        \n",
    "        C = np.sum((Y_train - o)**2)/(2*m)\n",
    "        \n",
    "        R = np.sum(w**2)/(2*m)\n",
    "\n",
    "        # Calculate the loss \n",
    "        # CODE HERE\n",
    "        L = C + lambdar*R\n",
    "        \n",
    "        # Backward pass and update the weights/bias\n",
    "        # CODE HERE\n",
    "        dCdZ = ((o - Y_train) * o * (1 - o))/(m)\n",
    "        dCdw = np.dot(dCdZ, X_train.T)\n",
    "        dRdw = w/m\n",
    "        dLdw = dCdw + lambdar*dRdw\n",
    "        \n",
    "        dLdb = (np.sum((o - Y_train) * o * (1 - o)))/m\n",
    "        \n",
    "        w -= lr*dLdw\n",
    "        b -= lr*dLdb\n",
    "        \n",
    "        print(\"Error of the epoch {0}: {1}\".format(epoch + 1, L))\n",
    "        \n",
    "    return w, b\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is a batch training and requires different hyperparameters, the result might not be comparable to the SGD trainings above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of the epoch 1: 0.1678707497382271\n",
      "Error of the epoch 2: 0.05099793891240988\n",
      "Error of the epoch 3: 0.05099029685926981\n",
      "Error of the epoch 4: 0.05098236124768441\n",
      "Error of the epoch 5: 0.05097411387531518\n",
      "Error of the epoch 6: 0.05096553499098012\n",
      "Error of the epoch 7: 0.05095660312598227\n",
      "Error of the epoch 8: 0.05094729490290709\n",
      "Error of the epoch 9: 0.05093758481830059\n",
      "Error of the epoch 10: 0.05092744499497388\n",
      "Error of the epoch 11: 0.05091684489886967\n",
      "Error of the epoch 12: 0.050905751014439275\n",
      "Error of the epoch 13: 0.050894126471271034\n",
      "Error of the epoch 14: 0.050881930613224616\n",
      "Error of the epoch 15: 0.05086911849948958\n",
      "Error of the epoch 16: 0.05085564032470598\n",
      "Error of the epoch 17: 0.050841440742436905\n",
      "Error of the epoch 18: 0.050826458072708164\n",
      "Error of the epoch 19: 0.0508106233698151\n",
      "Error of the epoch 20: 0.050793859320861404\n",
      "Error of the epoch 21: 0.05077607893816012\n",
      "Error of the epoch 22: 0.05075718399918558\n",
      "Error of the epoch 23: 0.05073706317552298\n",
      "Error of the epoch 24: 0.05071558977627017\n",
      "Error of the epoch 25: 0.050692619010285475\n",
      "Error of the epoch 26: 0.050667984643707045\n",
      "Error of the epoch 27: 0.05064149489168884\n",
      "Error of the epoch 28: 0.0506129273325904\n",
      "Error of the epoch 29: 0.05058202256354969\n",
      "Error of the epoch 30: 0.050548476220601345\n",
      "Error of the epoch 31: 0.05051192885262419\n",
      "Error of the epoch 32: 0.050471952948891355\n",
      "Error of the epoch 33: 0.05042803614810945\n",
      "Error of the epoch 34: 0.05037955926107399\n",
      "Error of the epoch 35: 0.05032576715391989\n",
      "Error of the epoch 36: 0.05026572965899833\n",
      "Error of the epoch 37: 0.050198288332562714\n",
      "Error of the epoch 38: 0.05012198277208587\n",
      "Error of the epoch 39: 0.05003494684137009\n",
      "Error of the epoch 40: 0.04993475964630393\n",
      "Error of the epoch 41: 0.04981822685517426\n",
      "Error of the epoch 42: 0.0496810519600528\n",
      "Error of the epoch 43: 0.049517328501189305\n",
      "Error of the epoch 44: 0.04931873138701856\n",
      "Error of the epoch 45: 0.049073183622413086\n",
      "Error of the epoch 46: 0.04876257008794456\n",
      "Error of the epoch 47: 0.04835863893928519\n",
      "Error of the epoch 48: 0.047815278152278776\n",
      "Error of the epoch 49: 0.04705315064224578\n",
      "Error of the epoch 50: 0.045927442679061105\n",
      "Error of the epoch 51: 0.04415769984413741\n",
      "Error of the epoch 52: 0.04118231746983545\n",
      "Error of the epoch 53: 0.0359812230529318\n",
      "Error of the epoch 54: 0.027809783603574487\n",
      "Error of the epoch 55: 0.019910509618326917\n",
      "Error of the epoch 56: 0.016747151217495936\n",
      "Error of the epoch 57: 0.01597657084388649\n",
      "Error of the epoch 58: 0.015563722143989041\n",
      "Error of the epoch 59: 0.015209552863426082\n",
      "Error of the epoch 60: 0.014891175497724719\n",
      "Error of the epoch 61: 0.014602636538979625\n",
      "Error of the epoch 62: 0.014339629868077472\n",
      "Error of the epoch 63: 0.01409865701877853\n",
      "Error of the epoch 64: 0.013876833770997164\n",
      "Error of the epoch 65: 0.013671762753831189\n",
      "Error of the epoch 66: 0.013481436424262411\n",
      "Error of the epoch 67: 0.013304161788088817\n",
      "Error of the epoch 68: 0.013138501519482737\n",
      "Error of the epoch 69: 0.01298322758316355\n",
      "Error of the epoch 70: 0.012837284450602802\n",
      "Error of the epoch 71: 0.0126997597238695\n",
      "Error of the epoch 72: 0.012569860515405462\n",
      "Error of the epoch 73: 0.012446894329458148\n",
      "Error of the epoch 74: 0.012330253487330921\n",
      "Error of the epoch 75: 0.01221940236061112\n",
      "Error of the epoch 76: 0.012113866843591871\n",
      "Error of the epoch 77: 0.012013225622481968\n",
      "Error of the epoch 78: 0.011917102895147729\n",
      "Error of the epoch 79: 0.011825162268711728\n",
      "Error of the epoch 80: 0.011737101618980292\n",
      "Error of the epoch 81: 0.011652648739542427\n",
      "Error of the epoch 82: 0.011571557642560926\n",
      "Error of the epoch 83: 0.01149360540005856\n",
      "Error of the epoch 84: 0.011418589435608912\n",
      "Error of the epoch 85: 0.01134632519306748\n",
      "Error of the epoch 86: 0.011276644122305253\n",
      "Error of the epoch 87: 0.011209391932579959\n",
      "Error of the epoch 88: 0.011144427072771471\n",
      "Error of the epoch 89: 0.011081619404656835\n",
      "Error of the epoch 90: 0.011020849041047569\n",
      "Error of the epoch 91: 0.010962005325221656\n",
      "Error of the epoch 92: 0.01090498593186203\n",
      "Error of the epoch 93: 0.01084969607282509\n",
      "Error of the epoch 94: 0.010796047793634656\n",
      "Error of the epoch 95: 0.010743959348731173\n",
      "Error of the epoch 96: 0.010693354645283704\n",
      "Error of the epoch 97: 0.010644162746858156\n",
      "Error of the epoch 98: 0.010596317429481727\n",
      "Error of the epoch 99: 0.0105497567836925\n",
      "Error of the epoch 100: 0.01050442285704892\n",
      "Error of the epoch 101: 0.010460261332323995\n",
      "Error of the epoch 102: 0.010417221237246357\n",
      "Error of the epoch 103: 0.010375254682193285\n",
      "Error of the epoch 104: 0.010334316622704615\n",
      "Error of the epoch 105: 0.010294364644083941\n",
      "Error of the epoch 106: 0.010255358765694802\n",
      "Error of the epoch 107: 0.010217261262853602\n",
      "Error of the epoch 108: 0.010180036504474688\n",
      "Error of the epoch 109: 0.010143650804842703\n",
      "Error of the epoch 110: 0.010108072288077852\n",
      "Error of the epoch 111: 0.010073270764025212\n",
      "Error of the epoch 112: 0.010039217614443631\n",
      "Error of the epoch 113: 0.010005885688495685\n",
      "Error of the epoch 114: 0.009973249206650417\n",
      "Error of the epoch 115: 0.00994128367220721\n",
      "Error of the epoch 116: 0.009909965789734064\n",
      "Error of the epoch 117: 0.009879273389788255\n",
      "Error of the epoch 118: 0.009849185359353262\n",
      "Error of the epoch 119: 0.009819681577484023\n",
      "Error of the epoch 120: 0.009790742855704106\n",
      "Error of the epoch 121: 0.009762350882744074\n",
      "Error of the epoch 122: 0.009734488173250774\n",
      "Error of the epoch 123: 0.009707138020133472\n",
      "Error of the epoch 124: 0.009680284450244757\n",
      "Error of the epoch 125: 0.009653912183122887\n",
      "Error of the epoch 126: 0.009628006592547797\n",
      "Error of the epoch 127: 0.009602553670685977\n",
      "Error of the epoch 128: 0.009577539994619917\n",
      "Error of the epoch 129: 0.009552952695076226\n",
      "Error of the epoch 130: 0.009528779427183233\n",
      "Error of the epoch 131: 0.009505008343103596\n",
      "Error of the epoch 132: 0.00948162806640104\n",
      "Error of the epoch 133: 0.009458627668012382\n",
      "Error of the epoch 134: 0.009435996643706979\n",
      "Error of the epoch 135: 0.009413724892925619\n",
      "Error of the epoch 136: 0.009391802698899892\n",
      "Error of the epoch 137: 0.009370220709961139\n",
      "Error of the epoch 138: 0.009348969921955521\n",
      "Error of the epoch 139: 0.00932804166168842\n",
      "Error of the epoch 140: 0.0093074275713275\n",
      "Error of the epoch 141: 0.009287119593699301\n",
      "Error of the epoch 142: 0.009267109958419334\n",
      "Error of the epoch 143: 0.009247391168800193\n",
      "Error of the epoch 144: 0.00922795598948654\n",
      "Error of the epoch 145: 0.009208797434769562\n",
      "Error of the epoch 146: 0.009189908757537071\n",
      "Error of the epoch 147: 0.009171283438818739\n",
      "Error of the epoch 148: 0.009152915177888748\n",
      "Error of the epoch 149: 0.00913479788289104\n",
      "Error of the epoch 150: 0.009116925661954762\n",
      "Error of the epoch 151: 0.009099292814769771\n",
      "Error of the epoch 152: 0.00908189382459429\n",
      "Error of the epoch 153: 0.009064723350668628\n",
      "Error of the epoch 154: 0.009047776221010778\n",
      "Error of the epoch 155: 0.00903104742557129\n",
      "Error of the epoch 156: 0.009014532109726376\n",
      "Error of the epoch 157: 0.008998225568089636\n",
      "Error of the epoch 158: 0.008982123238624053\n",
      "Error of the epoch 159: 0.008966220697037128\n",
      "Error of the epoch 160: 0.008950513651443214\n",
      "Error of the epoch 161: 0.008934997937277995\n",
      "Error of the epoch 162: 0.008919669512451186\n",
      "Error of the epoch 163: 0.008904524452724268\n",
      "Error of the epoch 164: 0.008889558947301077\n",
      "Error of the epoch 165: 0.008874769294619575\n",
      "Error of the epoch 166: 0.008860151898334168\n",
      "Error of the epoch 167: 0.0088457032634783\n",
      "Error of the epoch 168: 0.008831419992797894\n",
      "Error of the epoch 169: 0.00881729878324664\n",
      "Error of the epoch 170: 0.008803336422634728\n",
      "Error of the epoch 171: 0.00878952978642319\n",
      "Error of the epoch 172: 0.008775875834656291\n",
      "Error of the epoch 173: 0.008762371609025082\n",
      "Error of the epoch 174: 0.008749014230055448\n",
      "Error of the epoch 175: 0.008735800894414463\n",
      "Error of the epoch 176: 0.008722728872329185\n",
      "Error of the epoch 177: 0.008709795505112368\n",
      "Error of the epoch 178: 0.00869699820278988\n",
      "Error of the epoch 179: 0.008684334441824893\n",
      "Error of the epoch 180: 0.008671801762934216\n",
      "Error of the epoch 181: 0.008659397768992326\n",
      "Error of the epoch 182: 0.008647120123019025\n",
      "Error of the epoch 183: 0.008634966546246733\n",
      "Error of the epoch 184: 0.008622934816263727\n",
      "Error of the epoch 185: 0.008611022765229775\n",
      "Error of the epoch 186: 0.008599228278160911\n",
      "Error of the epoch 187: 0.008587549291280113\n",
      "Error of the epoch 188: 0.008575983790430949\n",
      "Error of the epoch 189: 0.008564529809551325\n",
      "Error of the epoch 190: 0.008553185429204689\n",
      "Error of the epoch 191: 0.008541948775166106\n",
      "Error of the epoch 192: 0.008530818017060769\n",
      "Error of the epoch 193: 0.008519791367052734\n",
      "Error of the epoch 194: 0.008508867078581598\n",
      "Error of the epoch 195: 0.008498043445145096\n",
      "Error of the epoch 196: 0.008487318799125673\n",
      "Error of the epoch 197: 0.008476691510659082\n",
      "Error of the epoch 198: 0.008466159986543325\n",
      "Error of the epoch 199: 0.008455722669186158\n",
      "Error of the epoch 200: 0.00844537803558959\n",
      "Error of the epoch 201: 0.008435124596369857\n",
      "Error of the epoch 202: 0.008424960894811342\n",
      "Error of the epoch 203: 0.008414885505953148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of the epoch 204: 0.0084048970357069\n",
      "Error of the epoch 205: 0.008394994120004582\n",
      "Error of the epoch 206: 0.008385175423975152\n",
      "Error of the epoch 207: 0.00837543964114884\n",
      "Error of the epoch 208: 0.008365785492687981\n",
      "Error of the epoch 209: 0.008356211726643343\n",
      "Error of the epoch 210: 0.008346717117235008\n",
      "Error of the epoch 211: 0.008337300464156757\n",
      "Error of the epoch 212: 0.008327960591903142\n",
      "Error of the epoch 213: 0.008318696349118283\n",
      "Error of the epoch 214: 0.00830950660796566\n",
      "Error of the epoch 215: 0.008300390263517988\n",
      "Error of the epoch 216: 0.00829134623316653\n",
      "Error of the epoch 217: 0.008282373456049015\n",
      "Error of the epoch 218: 0.008273470892495565\n",
      "Error of the epoch 219: 0.008264637523491858\n",
      "Error of the epoch 220: 0.008255872350158993\n",
      "Error of the epoch 221: 0.008247174393249367\n",
      "Error of the epoch 222: 0.008238542692658026\n",
      "Error of the epoch 223: 0.008229976306948905\n",
      "Error of the epoch 224: 0.008221474312895431\n",
      "Error of the epoch 225: 0.008213035805034965\n",
      "Error of the epoch 226: 0.00820465989523661\n",
      "Error of the epoch 227: 0.008196345712281889\n",
      "Error of the epoch 228: 0.008188092401457835\n",
      "Error of the epoch 229: 0.008179899124162109\n",
      "Error of the epoch 230: 0.008171765057519632\n",
      "Error of the epoch 231: 0.008163689394010446\n",
      "Error of the epoch 232: 0.008155671341108324\n",
      "Error of the epoch 233: 0.008147710120929796\n",
      "Error of the epoch 234: 0.00813980496989327\n",
      "Error of the epoch 235: 0.008131955138387818\n",
      "Error of the epoch 236: 0.008124159890451411\n",
      "Error of the epoch 237: 0.008116418503458182\n",
      "Error of the epoch 238: 0.008108730267814489\n",
      "Error of the epoch 239: 0.008101094486663466\n",
      "Error of the epoch 240: 0.008093510475597759\n",
      "Error of the epoch 241: 0.008085977562380196\n",
      "Error of the epoch 242: 0.008078495086672143\n",
      "Error of the epoch 243: 0.008071062399769282\n",
      "Error of the epoch 244: 0.008063678864344562\n",
      "Error of the epoch 245: 0.008056343854198114\n",
      "Error of the epoch 246: 0.0080490567540139\n",
      "Error of the epoch 247: 0.008041816959122866\n",
      "Error of the epoch 248: 0.008034623875272415\n",
      "Error of the epoch 249: 0.008027476918401982\n",
      "Error of the epoch 250: 0.008020375514424546\n",
      "Error of the epoch 251: 0.008013319099013858\n",
      "Error of the epoch 252: 0.00800630711739723\n",
      "Error of the epoch 253: 0.007999339024153724\n",
      "Error of the epoch 254: 0.007992414283017536\n",
      "Error of the epoch 255: 0.007985532366686466\n",
      "Error of the epoch 256: 0.007978692756635267\n",
      "Error of the epoch 257: 0.007971894942933776\n",
      "Error of the epoch 258: 0.007965138424069646\n",
      "Error of the epoch 259: 0.00795842270677555\n",
      "Error of the epoch 260: 0.007951747305860733\n",
      "Error of the epoch 261: 0.007945111744046784\n",
      "Error of the epoch 262: 0.007938515551807475\n",
      "Error of the epoch 263: 0.00793195826721259\n",
      "Error of the epoch 264: 0.007925439435775592\n",
      "Error of the epoch 265: 0.00791895861030503\n",
      "Error of the epoch 266: 0.007912515350759588\n",
      "Error of the epoch 267: 0.007906109224106637\n",
      "Error of the epoch 268: 0.007899739804184241\n",
      "Error of the epoch 269: 0.007893406671566459\n",
      "Error of the epoch 270: 0.007887109413431901\n",
      "Error of the epoch 271: 0.007880847623435414\n",
      "Error of the epoch 272: 0.007874620901582818\n",
      "Error of the epoch 273: 0.007868428854108607\n",
      "Error of the epoch 274: 0.00786227109335654\n",
      "Error of the epoch 275: 0.007856147237663024\n",
      "Error of the epoch 276: 0.007850056911243224\n",
      "Error of the epoch 277: 0.007843999744079828\n",
      "Error of the epoch 278: 0.007837975371814377\n",
      "Error of the epoch 279: 0.007831983435641107\n",
      "Error of the epoch 280: 0.007826023582203225\n",
      "Error of the epoch 281: 0.007820095463491569\n",
      "Error of the epoch 282: 0.007814198736745544\n",
      "Error of the epoch 283: 0.007808333064356338\n",
      "Error of the epoch 284: 0.007802498113772298\n",
      "Error of the epoch 285: 0.007796693557406441\n",
      "Error of the epoch 286: 0.007790919072546037\n",
      "Error of the epoch 287: 0.0077851743412642015\n",
      "Error of the epoch 288: 0.007779459050333452\n",
      "Error of the epoch 289: 0.0077737728911411695\n",
      "Error of the epoch 290: 0.007768115559606934\n",
      "Error of the epoch 291: 0.007762486756101653\n",
      "Error of the epoch 292: 0.00775688618536847\n",
      "Error of the epoch 293: 0.007751313556445382\n",
      "Error of the epoch 294: 0.007745768582589539\n",
      "Error of the epoch 295: 0.007740250981203173\n",
      "Error of the epoch 296: 0.007734760473761109\n",
      "Error of the epoch 297: 0.007729296785739844\n",
      "Error of the epoch 298: 0.007723859646548113\n",
      "Error of the epoch 299: 0.007718448789458954\n",
      "Error of the epoch 300: 0.0077130639515431846\n",
      "Error of the epoch 301: 0.007707704873604288\n",
      "Error of the epoch 302: 0.007702371300114665\n",
      "Error of the epoch 303: 0.007697062979153219\n",
      "Error of the epoch 304: 0.007691779662344227\n",
      "Error of the epoch 305: 0.007686521104797488\n",
      "Error of the epoch 306: 0.0076812870650496985\n",
      "Error of the epoch 307: 0.007676077305007036\n",
      "Error of the epoch 308: 0.0076708915898889216\n",
      "Error of the epoch 309: 0.007665729688172915\n",
      "Error of the epoch 310: 0.007660591371540741\n",
      "Error of the epoch 311: 0.007655476414825408\n",
      "Error of the epoch 312: 0.007650384595959377\n",
      "Error of the epoch 313: 0.007645315695923791\n",
      "Error of the epoch 314: 0.007640269498698699\n",
      "Error of the epoch 315: 0.007635245791214291\n",
      "Error of the epoch 316: 0.007630244363303083\n",
      "Error of the epoch 317: 0.007625265007653048\n",
      "Error of the epoch 318: 0.007620307519761693\n",
      "Error of the epoch 319: 0.007615371697890999\n",
      "Error of the epoch 320: 0.007610457343023264\n",
      "Error of the epoch 321: 0.0076055642588178105\n",
      "Error of the epoch 322: 0.007600692251568509\n",
      "Error of the epoch 323: 0.007595841130162141\n",
      "Error of the epoch 324: 0.007591010706037555\n",
      "Error of the epoch 325: 0.007586200793145601\n",
      "Error of the epoch 326: 0.00758141120790984\n",
      "Error of the epoch 327: 0.007576641769187986\n",
      "Error of the epoch 328: 0.007571892298234094\n",
      "Error of the epoch 329: 0.007567162618661444\n",
      "Error of the epoch 330: 0.0075624525564061415\n",
      "Error of the epoch 331: 0.0075577619396913764\n",
      "Error of the epoch 332: 0.0075530905989923645\n",
      "Error of the epoch 333: 0.007548438367001946\n",
      "Error of the epoch 334: 0.007543805078596791\n",
      "Error of the epoch 335: 0.007539190570804258\n",
      "Error of the epoch 336: 0.007534594682769851\n",
      "Error of the epoch 337: 0.007530017255725257\n",
      "Error of the epoch 338: 0.007525458132956991\n",
      "Error of the epoch 339: 0.007520917159775592\n",
      "Error of the epoch 340: 0.007516394183485377\n",
      "Error of the epoch 341: 0.007511889053354744\n",
      "Error of the epoch 342: 0.007507401620587006\n",
      "Error of the epoch 343: 0.0075029317382917455\n",
      "Error of the epoch 344: 0.007498479261456676\n",
      "Error of the epoch 345: 0.0074940440469200105\n",
      "Error of the epoch 346: 0.007489625953343302\n",
      "Error of the epoch 347: 0.007485224841184775\n",
      "Error of the epoch 348: 0.007480840572673116\n",
      "Error of the epoch 349: 0.0074764730117817335\n",
      "Error of the epoch 350: 0.007472122024203439\n",
      "Error of the epoch 351: 0.007467787477325599\n",
      "Error of the epoch 352: 0.0074634692402056795\n",
      "Error of the epoch 353: 0.007459167183547248\n",
      "Error of the epoch 354: 0.00745488117967635\n",
      "Error of the epoch 355: 0.007450611102518312\n",
      "Error of the epoch 356: 0.00744635682757492\n",
      "Error of the epoch 357: 0.007442118231902008\n",
      "Error of the epoch 358: 0.007437895194087381\n",
      "Error of the epoch 359: 0.00743368759422916\n",
      "Error of the epoch 360: 0.007429495313914439\n",
      "Error of the epoch 361: 0.007425318236198332\n",
      "Error of the epoch 362: 0.007421156245583343\n",
      "Error of the epoch 363: 0.007417009227999091\n",
      "Error of the epoch 364: 0.007412877070782359\n",
      "Error of the epoch 365: 0.007408759662657463\n",
      "Error of the epoch 366: 0.007404656893716955\n",
      "Error of the epoch 367: 0.007400568655402629\n",
      "Error of the epoch 368: 0.007396494840486829\n",
      "Error of the epoch 369: 0.007392435343054065\n",
      "Error of the epoch 370: 0.007388390058482919\n",
      "Error of the epoch 371: 0.007384358883428236\n",
      "Error of the epoch 372: 0.007380341715803599\n",
      "Error of the epoch 373: 0.0073763384547640845\n",
      "Error of the epoch 374: 0.007372349000689278\n",
      "Error of the epoch 375: 0.007368373255166568\n",
      "Error of the epoch 376: 0.007364411120974682\n",
      "Error of the epoch 377: 0.0073604625020674995\n",
      "Error of the epoch 378: 0.007356527303558096\n",
      "Error of the epoch 379: 0.007352605431703037\n",
      "Error of the epoch 380: 0.007348696793886918\n",
      "Error of the epoch 381: 0.007344801298607127\n",
      "Error of the epoch 382: 0.007340918855458852\n",
      "Error of the epoch 383: 0.007337049375120305\n",
      "Error of the epoch 384: 0.007333192769338167\n",
      "Error of the epoch 385: 0.007329348950913253\n",
      "Error of the epoch 386: 0.007325517833686391\n",
      "Error of the epoch 387: 0.007321699332524511\n",
      "Error of the epoch 388: 0.0073178933633069225\n",
      "Error of the epoch 389: 0.007314099842911828\n",
      "Error of the epoch 390: 0.007310318689202988\n",
      "Error of the epoch 391: 0.007306549821016617\n",
      "Error of the epoch 392: 0.007302793158148452\n",
      "Error of the epoch 393: 0.007299048621341004\n",
      "Error of the epoch 394: 0.007295316132271001\n",
      "Error of the epoch 395: 0.007291595613537002\n",
      "Error of the epoch 396: 0.007287886988647196\n",
      "Error of the epoch 397: 0.007284190182007362\n",
      "Error of the epoch 398: 0.0072805051189089994\n",
      "Error of the epoch 399: 0.007276831725517638\n",
      "Error of the epoch 400: 0.0072731699288612894\n",
      "Error of the epoch 401: 0.00726951965681908\n",
      "Error of the epoch 402: 0.007265880838110013\n",
      "Error of the epoch 403: 0.007262253402281923\n",
      "Error of the epoch 404: 0.007258637279700535\n",
      "Error of the epoch 405: 0.007255032401538719\n",
      "Error of the epoch 406: 0.007251438699765845\n",
      "Error of the epoch 407: 0.007247856107137324\n",
      "Error of the epoch 408: 0.007244284557184252\n",
      "Error of the epoch 409: 0.0072407239842032164\n",
      "Error of the epoch 410: 0.007237174323246227\n",
      "Error of the epoch 411: 0.007233635510110782\n",
      "Error of the epoch 412: 0.0072301074813300665\n",
      "Error of the epoch 413: 0.007226590174163277\n",
      "Error of the epoch 414: 0.007223083526586073\n",
      "Error of the epoch 415: 0.00721958747728115\n",
      "Error of the epoch 416: 0.007216101965628941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of the epoch 417: 0.00721262693169843\n",
      "Error of the epoch 418: 0.007209162316238089\n",
      "Error of the epoch 419: 0.007205708060666927\n",
      "Error of the epoch 420: 0.007202264107065644\n",
      "Error of the epoch 421: 0.00719883039816793\n",
      "Error of the epoch 422: 0.007195406877351826\n",
      "Error of the epoch 423: 0.007191993488631229\n",
      "Error of the epoch 424: 0.007188590176647492\n",
      "Error of the epoch 425: 0.007185196886661125\n",
      "Error of the epoch 426: 0.007181813564543607\n",
      "Error of the epoch 427: 0.007178440156769285\n",
      "Error of the epoch 428: 0.007175076610407399\n",
      "Error of the epoch 429: 0.007171722873114169\n",
      "Error of the epoch 430: 0.007168378893125014\n",
      "Error of the epoch 431: 0.007165044619246838\n",
      "Error of the epoch 432: 0.007161720000850429\n",
      "Error of the epoch 433: 0.007158404987862942\n",
      "Error of the epoch 434: 0.007155099530760473\n",
      "Error of the epoch 435: 0.007151803580560716\n",
      "Error of the epoch 436: 0.007148517088815726\n",
      "Error of the epoch 437: 0.0071452400076047525\n",
      "Error of the epoch 438: 0.00714197228952716\n",
      "Error of the epoch 439: 0.0071387138876954455\n",
      "Error of the epoch 440: 0.007135464755728323\n",
      "Error of the epoch 441: 0.007132224847743897\n",
      "Error of the epoch 442: 0.007128994118352926\n",
      "Error of the epoch 443: 0.007125772522652139\n",
      "Error of the epoch 444: 0.00712256001621767\n",
      "Error of the epoch 445: 0.007119356555098528\n",
      "Error of the epoch 446: 0.007116162095810177\n",
      "Error of the epoch 447: 0.007112976595328172\n",
      "Error of the epoch 448: 0.007109800011081877\n",
      "Error of the epoch 449: 0.007106632300948257\n",
      "Error of the epoch 450: 0.0071034734232457335\n",
      "Error of the epoch 451: 0.007100323336728127\n",
      "Error of the epoch 452: 0.007097182000578662\n",
      "Error of the epoch 453: 0.007094049374404029\n",
      "Error of the epoch 454: 0.0070909254182285495\n",
      "Error of the epoch 455: 0.0070878100924883685\n",
      "Error of the epoch 456: 0.007084703358025747\n",
      "Error of the epoch 457: 0.007081605176083402\n",
      "Error of the epoch 458: 0.007078515508298919\n",
      "Error of the epoch 459: 0.007075434316699234\n",
      "Error of the epoch 460: 0.007072361563695172\n",
      "Error of the epoch 461: 0.007069297212076049\n",
      "Error of the epoch 462: 0.007066241225004345\n",
      "Error of the epoch 463: 0.007063193566010437\n",
      "Error of the epoch 464: 0.007060154198987381\n",
      "Error of the epoch 465: 0.007057123088185778\n",
      "Error of the epoch 466: 0.0070541001982086775\n",
      "Error of the epoch 467: 0.007051085494006558\n",
      "Error of the epoch 468: 0.007048078940872355\n",
      "Error of the epoch 469: 0.007045080504436555\n",
      "Error of the epoch 470: 0.007042090150662344\n",
      "Error of the epoch 471: 0.007039107845840812\n",
      "Error of the epoch 472: 0.007036133556586219\n",
      "Error of the epoch 473: 0.0070331672498313135\n",
      "Error of the epoch 474: 0.007030208892822712\n",
      "Error of the epoch 475: 0.007027258453116323\n",
      "Error of the epoch 476: 0.0070243158985728365\n",
      "Error of the epoch 477: 0.0070213811973532676\n",
      "Error of the epoch 478: 0.007018454317914543\n",
      "Error of the epoch 479: 0.007015535229005158\n",
      "Error of the epoch 480: 0.007012623899660863\n",
      "Error of the epoch 481: 0.007009720299200432\n",
      "Error of the epoch 482: 0.007006824397221454\n",
      "Error of the epoch 483: 0.007003936163596197\n",
      "Error of the epoch 484: 0.007001055568467515\n",
      "Error of the epoch 485: 0.006998182582244801\n",
      "Error of the epoch 486: 0.0069953171756000024\n",
      "Error of the epoch 487: 0.006992459319463675\n",
      "Error of the epoch 488: 0.006989608985021086\n",
      "Error of the epoch 489: 0.006986766143708384\n",
      "Error of the epoch 490: 0.0069839307672087915\n",
      "Error of the epoch 491: 0.006981102827448872\n",
      "Error of the epoch 492: 0.006978282296594817\n",
      "Error of the epoch 493: 0.006975469147048804\n",
      "Error of the epoch 494: 0.0069726633514453976\n",
      "Error of the epoch 495: 0.006969864882647982\n",
      "Error of the epoch 496: 0.006967073713745262\n",
      "Error of the epoch 497: 0.00696428981804779\n",
      "Error of the epoch 498: 0.006961513169084558\n",
      "Error of the epoch 499: 0.006958743740599609\n",
      "Error of the epoch 500: 0.006955981506548734\n",
      "Error of the epoch 501: 0.006953226441096166\n",
      "Error of the epoch 502: 0.006950478518611352\n",
      "Error of the epoch 503: 0.006947737713665764\n",
      "Error of the epoch 504: 0.0069450040010297365\n",
      "Error of the epoch 505: 0.006942277355669369\n",
      "Error of the epoch 506: 0.006939557752743459\n",
      "Error of the epoch 507: 0.006936845167600483\n",
      "Error of the epoch 508: 0.006934139575775612\n",
      "Error of the epoch 509: 0.0069314409529877795\n",
      "Error of the epoch 510: 0.006928749275136794\n",
      "Error of the epoch 511: 0.006926064518300466\n",
      "Error of the epoch 512: 0.0069233866587318175\n",
      "Error of the epoch 513: 0.006920715672856298\n",
      "Error of the epoch 514: 0.00691805153726906\n",
      "Error of the epoch 515: 0.006915394228732259\n",
      "Error of the epoch 516: 0.006912743724172418\n",
      "Error of the epoch 517: 0.006910100000677804\n",
      "Error of the epoch 518: 0.00690746303549586\n",
      "Error of the epoch 519: 0.006904832806030671\n",
      "Error of the epoch 520: 0.006902209289840477\n",
      "Error of the epoch 521: 0.006899592464635205\n",
      "Error of the epoch 522: 0.006896982308274059\n",
      "Error of the epoch 523: 0.006894378798763141\n",
      "Error of the epoch 524: 0.006891781914253101\n",
      "Error of the epoch 525: 0.006889191633036836\n",
      "Error of the epoch 526: 0.006886607933547219\n",
      "Error of the epoch 527: 0.006884030794354868\n",
      "Error of the epoch 528: 0.006881460194165947\n",
      "Error of the epoch 529: 0.006878896111820007\n",
      "Error of the epoch 530: 0.0068763385262878545\n",
      "Error of the epoch 531: 0.0068737874166694725\n",
      "Error of the epoch 532: 0.006871242762191953\n",
      "Error of the epoch 533: 0.00686870454220748\n",
      "Error of the epoch 534: 0.006866172736191344\n",
      "Error of the epoch 535: 0.006863647323739989\n",
      "Error of the epoch 536: 0.006861128284569086\n",
      "Error of the epoch 537: 0.006858615598511657\n",
      "Error of the epoch 538: 0.0068561092455162054\n",
      "Error of the epoch 539: 0.006853609205644917\n",
      "Error of the epoch 540: 0.006851115459071845\n",
      "Error of the epoch 541: 0.006848627986081175\n",
      "Error of the epoch 542: 0.006846146767065485\n",
      "Error of the epoch 543: 0.006843671782524053\n",
      "Error of the epoch 544: 0.006841203013061199\n",
      "Error of the epoch 545: 0.006838740439384649\n",
      "Error of the epoch 546: 0.006836284042303924\n",
      "Error of the epoch 547: 0.006833833802728775\n",
      "Error of the epoch 548: 0.006831389701667645\n",
      "Error of the epoch 549: 0.006828951720226135\n",
      "Error of the epoch 550: 0.0068265198396055375\n",
      "Error of the epoch 551: 0.006824094041101369\n",
      "Error of the epoch 552: 0.006821674306101942\n",
      "Error of the epoch 553: 0.0068192606160869685\n",
      "Error of the epoch 554: 0.0068168529526261784\n",
      "Error of the epoch 555: 0.0068144512973779825\n",
      "Error of the epoch 556: 0.006812055632088142\n",
      "Error of the epoch 557: 0.006809665938588485\n",
      "Error of the epoch 558: 0.006807282198795634\n",
      "Error of the epoch 559: 0.006804904394709765\n",
      "Error of the epoch 560: 0.006802532508413395\n",
      "Error of the epoch 561: 0.006800166522070185\n",
      "Error of the epoch 562: 0.006797806417923782\n",
      "Error of the epoch 563: 0.006795452178296675\n",
      "Error of the epoch 564: 0.006793103785589071\n",
      "Error of the epoch 565: 0.006790761222277816\n",
      "Error of the epoch 566: 0.006788424470915308\n",
      "Error of the epoch 567: 0.006786093514128467\n",
      "Error of the epoch 568: 0.0067837683346177\n",
      "Error of the epoch 569: 0.0067814489151559005\n",
      "Error of the epoch 570: 0.0067791352385874765\n",
      "Error of the epoch 571: 0.0067768272878273896\n",
      "Error of the epoch 572: 0.006774525045860211\n",
      "Error of the epoch 573: 0.00677222849573922\n",
      "Error of the epoch 574: 0.0067699376205855024\n",
      "Error of the epoch 575: 0.006767652403587082\n",
      "Error of the epoch 576: 0.00676537282799806\n",
      "Error of the epoch 577: 0.006763098877137788\n",
      "Error of the epoch 578: 0.006760830534390054\n",
      "Error of the epoch 579: 0.006758567783202287\n",
      "Error of the epoch 580: 0.00675631060708478\n",
      "Error of the epoch 581: 0.006754058989609931\n",
      "Error of the epoch 582: 0.006751812914411516\n",
      "Error of the epoch 583: 0.006749572365183955\n",
      "Error of the epoch 584: 0.0067473373256816144\n",
      "Error of the epoch 585: 0.006745107779718119\n",
      "Error of the epoch 586: 0.006742883711165692\n",
      "Error of the epoch 587: 0.0067406651039544924\n",
      "Error of the epoch 588: 0.006738451942071979\n",
      "Error of the epoch 589: 0.006736244209562307\n",
      "Error of the epoch 590: 0.006734041890525706\n",
      "Error of the epoch 591: 0.0067318449691179\n",
      "Error of the epoch 592: 0.006729653429549538\n",
      "Error of the epoch 593: 0.0067274672560856275\n",
      "Error of the epoch 594: 0.006725286433045\n",
      "Error of the epoch 595: 0.006723110944799778\n",
      "Error of the epoch 596: 0.006720940775774858\n",
      "Error of the epoch 597: 0.00671877591044742\n",
      "Error of the epoch 598: 0.006716616333346424\n",
      "Error of the epoch 599: 0.006714462029052147\n",
      "Error of the epoch 600: 0.006712312982195725\n",
      "Error of the epoch 601: 0.006710169177458691\n",
      "Error of the epoch 602: 0.006708030599572552\n",
      "Error of the epoch 603: 0.006705897233318357\n",
      "Error of the epoch 604: 0.006703769063526291\n",
      "Error of the epoch 605: 0.006701646075075267\n",
      "Error of the epoch 606: 0.006699528252892544\n",
      "Error of the epoch 607: 0.0066974155819533475\n",
      "Error of the epoch 608: 0.006695308047280497\n",
      "Error of the epoch 609: 0.0066932056339440585\n",
      "Error of the epoch 610: 0.006691108327060989\n",
      "Error of the epoch 611: 0.006689016111794808\n",
      "Error of the epoch 612: 0.006686928973355266\n",
      "Error of the epoch 613: 0.006684846896998034\n",
      "Error of the epoch 614: 0.006682769868024387\n",
      "Error of the epoch 615: 0.006680697871780913\n",
      "Error of the epoch 616: 0.006678630893659228\n",
      "Error of the epoch 617: 0.006676568919095682\n",
      "Error of the epoch 618: 0.006674511933571098\n",
      "Error of the epoch 619: 0.006672459922610507\n",
      "Error of the epoch 620: 0.006670412871782888\n",
      "Error of the epoch 621: 0.0066683707667009266\n",
      "Error of the epoch 622: 0.006666333593020768\n",
      "Error of the epoch 623: 0.006664301336441788\n",
      "Error of the epoch 624: 0.006662273982706368\n",
      "Error of the epoch 625: 0.006660251517599675\n",
      "Error of the epoch 626: 0.006658233926949448\n",
      "Error of the epoch 627: 0.006656221196625802\n",
      "Error of the epoch 628: 0.006654213312541014\n",
      "Error of the epoch 629: 0.006652210260649346\n",
      "Error of the epoch 630: 0.006650212026946846\n",
      "Error of the epoch 631: 0.0066482185974711784\n",
      "Error of the epoch 632: 0.00664622995830144\n",
      "Error of the epoch 633: 0.006644246095557996\n",
      "Error of the epoch 634: 0.006642266995402314\n",
      "Error of the epoch 635: 0.00664029264403681\n",
      "Error of the epoch 636: 0.006638323027704682\n",
      "Error of the epoch 637: 0.006636358132689777\n",
      "Error of the epoch 638: 0.006634397945316437\n",
      "Error of the epoch 639: 0.006632442451949356\n",
      "Error of the epoch 640: 0.006630491638993458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of the epoch 641: 0.006628545492893752\n",
      "Error of the epoch 642: 0.0066266040001352125\n",
      "Error of the epoch 643: 0.006624667147242654\n",
      "Error of the epoch 644: 0.0066227349207806105\n",
      "Error of the epoch 645: 0.006620807307353225\n",
      "Error of the epoch 646: 0.006618884293604126\n",
      "Error of the epoch 647: 0.006616965866216331\n",
      "Error of the epoch 648: 0.006615052011912138\n",
      "Error of the epoch 649: 0.006613142717453013\n",
      "Error of the epoch 650: 0.006611237969639499\n",
      "Error of the epoch 651: 0.006609337755311124\n",
      "Error of the epoch 652: 0.006607442061346298\n",
      "Error of the epoch 653: 0.006605550874662219\n",
      "Error of the epoch 654: 0.006603664182214798\n",
      "Error of the epoch 655: 0.006601781970998559\n",
      "Error of the epoch 656: 0.006599904228046558\n",
      "Error of the epoch 657: 0.0065980309404303095\n",
      "Error of the epoch 658: 0.006596162095259694\n",
      "Error of the epoch 659: 0.006594297679682887\n",
      "Error of the epoch 660: 0.006592437680886284\n",
      "Error of the epoch 661: 0.006590582086094419\n",
      "Error of the epoch 662: 0.006588730882569903\n",
      "Error of the epoch 663: 0.006586884057613338\n",
      "Error of the epoch 664: 0.0065850415985632665\n",
      "Error of the epoch 665: 0.006583203492796084\n",
      "Error of the epoch 666: 0.006581369727725984\n",
      "Error of the epoch 667: 0.006579540290804889\n",
      "Error of the epoch 668: 0.006577715169522388\n",
      "Error of the epoch 669: 0.006575894351405668\n",
      "Error of the epoch 670: 0.00657407782401946\n",
      "Error of the epoch 671: 0.006572265574965968\n",
      "Error of the epoch 672: 0.006570457591884818\n",
      "Error of the epoch 673: 0.006568653862452987\n",
      "Error of the epoch 674: 0.006566854374384759\n",
      "Error of the epoch 675: 0.006565059115431654\n",
      "Error of the epoch 676: 0.006563268073382372\n",
      "Error of the epoch 677: 0.0065614812360627415\n",
      "Error of the epoch 678: 0.006559698591335664\n",
      "Error of the epoch 679: 0.006557920127101044\n",
      "Error of the epoch 680: 0.006556145831295753\n",
      "Error of the epoch 681: 0.006554375691893556\n",
      "Error of the epoch 682: 0.006552609696905067\n",
      "Error of the epoch 683: 0.006550847834377691\n",
      "Error of the epoch 684: 0.006549090092395569\n",
      "Error of the epoch 685: 0.006547336459079522\n",
      "Error of the epoch 686: 0.006545586922587\n",
      "Error of the epoch 687: 0.0065438414711120226\n",
      "Error of the epoch 688: 0.006542100092885125\n",
      "Error of the epoch 689: 0.006540362776173311\n",
      "Error of the epoch 690: 0.006538629509279987\n",
      "Error of the epoch 691: 0.006536900280544913\n",
      "Error of the epoch 692: 0.006535175078344149\n",
      "Error of the epoch 693: 0.006533453891089993\n",
      "Error of the epoch 694: 0.006531736707230935\n",
      "Error of the epoch 695: 0.006530023515251596\n",
      "Error of the epoch 696: 0.006528314303672668\n",
      "Error of the epoch 697: 0.006526609061050863\n",
      "Error of the epoch 698: 0.006524907775978863\n",
      "Error of the epoch 699: 0.006523210437085243\n",
      "Error of the epoch 700: 0.006521517033034434\n",
      "Error of the epoch 701: 0.006519827552526655\n",
      "Error of the epoch 702: 0.006518141984297856\n",
      "Error of the epoch 703: 0.00651646031711966\n",
      "Error of the epoch 704: 0.006514782539799306\n",
      "Error of the epoch 705: 0.006513108641179584\n",
      "Error of the epoch 706: 0.006511438610138779\n",
      "Error of the epoch 707: 0.006509772435590608\n",
      "Error of the epoch 708: 0.006508110106484164\n",
      "Error of the epoch 709: 0.006506451611803843\n",
      "Error of the epoch 710: 0.006504796940569292\n",
      "Error of the epoch 711: 0.0065031460818353445\n",
      "Error of the epoch 712: 0.0065014990246919525\n",
      "Error of the epoch 713: 0.006499855758264125\n",
      "Error of the epoch 714: 0.006498216271711861\n",
      "Error of the epoch 715: 0.006496580554230088\n",
      "Error of the epoch 716: 0.006494948595048594\n",
      "Error of the epoch 717: 0.006493320383431955\n",
      "Error of the epoch 718: 0.006491695908679481\n",
      "Error of the epoch 719: 0.006490075160125135\n",
      "Error of the epoch 720: 0.006488458127137468\n",
      "Error of the epoch 721: 0.006486844799119553\n",
      "Error of the epoch 722: 0.006485235165508914\n",
      "Error of the epoch 723: 0.006483629215777448\n",
      "Error of the epoch 724: 0.006482026939431367\n",
      "Error of the epoch 725: 0.00648042832601111\n",
      "Error of the epoch 726: 0.006478833365091289\n",
      "Error of the epoch 727: 0.0064772420462805924\n",
      "Error of the epoch 728: 0.006475654359221733\n",
      "Error of the epoch 729: 0.00647407029359136\n",
      "Error of the epoch 730: 0.0064724898390999845\n",
      "Error of the epoch 731: 0.006470912985491912\n",
      "Error of the epoch 732: 0.006469339722545153\n",
      "Error of the epoch 733: 0.006467770040071355\n",
      "Error of the epoch 734: 0.006466203927915724\n",
      "Error of the epoch 735: 0.006464641375956933\n",
      "Error of the epoch 736: 0.006463082374107064\n",
      "Error of the epoch 737: 0.006461526912311506\n",
      "Error of the epoch 738: 0.006459974980548887\n",
      "Error of the epoch 739: 0.006458426568830996\n",
      "Error of the epoch 740: 0.006456881667202682\n",
      "Error of the epoch 741: 0.0064553402657417935\n",
      "Error of the epoch 742: 0.00645380235455908\n",
      "Error of the epoch 743: 0.0064522679237981155\n",
      "Error of the epoch 744: 0.006450736963635207\n",
      "Error of the epoch 745: 0.006449209464279317\n",
      "Error of the epoch 746: 0.006447685415971974\n",
      "Error of the epoch 747: 0.006446164808987183\n",
      "Error of the epoch 748: 0.006444647633631343\n",
      "Error of the epoch 749: 0.006443133880243159\n",
      "Error of the epoch 750: 0.00644162353919355\n",
      "Error of the epoch 751: 0.006440116600885559\n",
      "Error of the epoch 752: 0.006438613055754279\n",
      "Error of the epoch 753: 0.006437112894266736\n",
      "Error of the epoch 754: 0.006435616106921824\n",
      "Error of the epoch 755: 0.0064341226842502\n",
      "Error of the epoch 756: 0.006432632616814196\n",
      "Error of the epoch 757: 0.006431145895207726\n",
      "Error of the epoch 758: 0.006429662510056196\n",
      "Error of the epoch 759: 0.006428182452016411\n",
      "Error of the epoch 760: 0.006426705711776474\n",
      "Error of the epoch 761: 0.006425232280055703\n",
      "Error of the epoch 762: 0.006423762147604532\n",
      "Error of the epoch 763: 0.006422295305204411\n",
      "Error of the epoch 764: 0.006420831743667717\n",
      "Error of the epoch 765: 0.0064193714538376585\n",
      "Error of the epoch 766: 0.006417914426588175\n",
      "Error of the epoch 767: 0.006416460652823842\n",
      "Error of the epoch 768: 0.006415010123479776\n",
      "Error of the epoch 769: 0.006413562829521534\n",
      "Error of the epoch 770: 0.006412118761945021\n",
      "Error of the epoch 771: 0.006410677911776384\n",
      "Error of the epoch 772: 0.006409240270071917\n",
      "Error of the epoch 773: 0.00640780582791797\n",
      "Error of the epoch 774: 0.006406374576430836\n",
      "Error of the epoch 775: 0.00640494650675666\n",
      "Error of the epoch 776: 0.006403521610071338\n",
      "Error of the epoch 777: 0.006402099877580417\n",
      "Error of the epoch 778: 0.006400681300518993\n",
      "Error of the epoch 779: 0.006399265870151613\n",
      "Error of the epoch 780: 0.0063978535777721715\n",
      "Error of the epoch 781: 0.006396444414703811\n",
      "Error of the epoch 782: 0.006395038372298817\n",
      "Error of the epoch 783: 0.006393635441938524\n",
      "Error of the epoch 784: 0.006392235615033205\n",
      "Error of the epoch 785: 0.006390838883021978\n",
      "Error of the epoch 786: 0.006389445237372693\n",
      "Error of the epoch 787: 0.006388054669581844\n",
      "Error of the epoch 788: 0.006386667171174448\n",
      "Error of the epoch 789: 0.006385282733703961\n",
      "Error of the epoch 790: 0.006383901348752161\n",
      "Error of the epoch 791: 0.0063825230079290534\n",
      "Error of the epoch 792: 0.006381147702872763\n",
      "Error of the epoch 793: 0.006379775425249434\n",
      "Error of the epoch 794: 0.006378406166753125\n",
      "Error of the epoch 795: 0.006377039919105701\n",
      "Error of the epoch 796: 0.006375676674056739\n",
      "Error of the epoch 797: 0.006374316423383419\n",
      "Error of the epoch 798: 0.0063729591588904165\n",
      "Error of the epoch 799: 0.006371604872409807\n",
      "Error of the epoch 800: 0.006370253555800957\n",
      "Error of the epoch 801: 0.006368905200950421\n",
      "Error of the epoch 802: 0.006367559799771833\n",
      "Error of the epoch 803: 0.0063662173442058136\n",
      "Error of the epoch 804: 0.006364877826219855\n",
      "Error of the epoch 805: 0.006363541237808222\n",
      "Error of the epoch 806: 0.006362207570991848\n",
      "Error of the epoch 807: 0.006360876817818232\n",
      "Error of the epoch 808: 0.006359548970361327\n",
      "Error of the epoch 809: 0.00635822402072145\n",
      "Error of the epoch 810: 0.006356901961025162\n",
      "Error of the epoch 811: 0.00635558278342518\n",
      "Error of the epoch 812: 0.006354266480100259\n",
      "Error of the epoch 813: 0.0063529530432551\n",
      "Error of the epoch 814: 0.006351642465120238\n",
      "Error of the epoch 815: 0.006350334737951941\n",
      "Error of the epoch 816: 0.006349029854032115\n",
      "Error of the epoch 817: 0.006347727805668179\n",
      "Error of the epoch 818: 0.006346428585192991\n",
      "Error of the epoch 819: 0.00634513218496472\n",
      "Error of the epoch 820: 0.006343838597366753\n",
      "Error of the epoch 821: 0.0063425478148075995\n",
      "Error of the epoch 822: 0.006341259829720773\n",
      "Error of the epoch 823: 0.006339974634564701\n",
      "Error of the epoch 824: 0.006338692221822619\n",
      "Error of the epoch 825: 0.006337412584002468\n",
      "Error of the epoch 826: 0.006336135713636788\n",
      "Error of the epoch 827: 0.006334861603282626\n",
      "Error of the epoch 828: 0.006333590245521429\n",
      "Error of the epoch 829: 0.006332321632958935\n",
      "Error of the epoch 830: 0.006331055758225088\n",
      "Error of the epoch 831: 0.006329792613973925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of the epoch 832: 0.00632853219288348\n",
      "Error of the epoch 833: 0.006327274487655678\n",
      "Error of the epoch 834: 0.006326019491016245\n",
      "Error of the epoch 835: 0.006324767195714594\n",
      "Error of the epoch 836: 0.006323517594523742\n",
      "Error of the epoch 837: 0.006322270680240193\n",
      "Error of the epoch 838: 0.006321026445683853\n",
      "Error of the epoch 839: 0.0063197848836979206\n",
      "Error of the epoch 840: 0.006318545987148794\n",
      "Error of the epoch 841: 0.006317309748925973\n",
      "Error of the epoch 842: 0.006316076161941956\n",
      "Error of the epoch 843: 0.006314845219132146\n",
      "Error of the epoch 844: 0.006313616913454751\n",
      "Error of the epoch 845: 0.00631239123789069\n",
      "Error of the epoch 846: 0.00631116818544349\n",
      "Error of the epoch 847: 0.006309947749139193\n",
      "Error of the epoch 848: 0.006308729922026263\n",
      "Error of the epoch 849: 0.0063075146971754825\n",
      "Error of the epoch 850: 0.006306302067679858\n",
      "Error of the epoch 851: 0.006305092026654535\n",
      "Error of the epoch 852: 0.006303884567236685\n",
      "Error of the epoch 853: 0.006302679682585427\n",
      "Error of the epoch 854: 0.006301477365881723\n",
      "Error of the epoch 855: 0.006300277610328289\n",
      "Error of the epoch 856: 0.006299080409149497\n",
      "Error of the epoch 857: 0.006297885755591289\n",
      "Error of the epoch 858: 0.006296693642921071\n",
      "Error of the epoch 859: 0.006295504064427637\n",
      "Error of the epoch 860: 0.006294317013421063\n",
      "Error of the epoch 861: 0.006293132483232618\n",
      "Error of the epoch 862: 0.006291950467214678\n",
      "Error of the epoch 863: 0.006290770958740628\n",
      "Error of the epoch 864: 0.006289593951204778\n",
      "Error of the epoch 865: 0.006288419438022264\n",
      "Error of the epoch 866: 0.006287247412628964\n",
      "Error of the epoch 867: 0.006286077868481409\n",
      "Error of the epoch 868: 0.00628491079905669\n",
      "Error of the epoch 869: 0.006283746197852368\n",
      "Error of the epoch 870: 0.0062825840583863885\n",
      "Error of the epoch 871: 0.006281424374196995\n",
      "Error of the epoch 872: 0.006280267138842638\n",
      "Error of the epoch 873: 0.006279112345901886\n",
      "Error of the epoch 874: 0.006277959988973343\n",
      "Error of the epoch 875: 0.00627681006167556\n",
      "Error of the epoch 876: 0.006275662557646951\n",
      "Error of the epoch 877: 0.0062745174705456964\n",
      "Error of the epoch 878: 0.006273374794049673\n",
      "Error of the epoch 879: 0.006272234521856365\n",
      "Error of the epoch 880: 0.006271096647682767\n",
      "Error of the epoch 881: 0.006269961165265321\n",
      "Error of the epoch 882: 0.006268828068359809\n",
      "Error of the epoch 883: 0.006267697350741291\n",
      "Error of the epoch 884: 0.00626656900620401\n",
      "Error of the epoch 885: 0.006265443028561312\n",
      "Error of the epoch 886: 0.006264319411645566\n",
      "Error of the epoch 887: 0.006263198149308076\n",
      "Error of the epoch 888: 0.006262079235419014\n",
      "Error of the epoch 889: 0.006260962663867321\n",
      "Error of the epoch 890: 0.006259848428560639\n",
      "Error of the epoch 891: 0.0062587365234252285\n",
      "Error of the epoch 892: 0.0062576269424058865\n",
      "Error of the epoch 893: 0.006256519679465869\n",
      "Error of the epoch 894: 0.006255414728586815\n",
      "Error of the epoch 895: 0.006254312083768661\n",
      "Error of the epoch 896: 0.006253211739029573\n",
      "Error of the epoch 897: 0.006252113688405859\n",
      "Error of the epoch 898: 0.006251017925951901\n",
      "Error of the epoch 899: 0.006249924445740073\n",
      "Error of the epoch 900: 0.0062488332418606666\n",
      "Error of the epoch 901: 0.006247744308421814\n",
      "Error of the epoch 902: 0.006246657639549416\n",
      "Error of the epoch 903: 0.006245573229387062\n",
      "Error of the epoch 904: 0.006244491072095965\n",
      "Error of the epoch 905: 0.006243411161854873\n",
      "Error of the epoch 906: 0.00624233349286001\n",
      "Error of the epoch 907: 0.006241258059324995\n",
      "Error of the epoch 908: 0.006240184855480771\n",
      "Error of the epoch 909: 0.006239113875575533\n",
      "Error of the epoch 910: 0.006238045113874656\n",
      "Error of the epoch 911: 0.006236978564660624\n",
      "Error of the epoch 912: 0.006235914222232957\n",
      "Error of the epoch 913: 0.0062348520809081456\n",
      "Error of the epoch 914: 0.006233792135019575\n",
      "Error of the epoch 915: 0.006232734378917457\n",
      "Error of the epoch 916: 0.0062316788069687636\n",
      "Error of the epoch 917: 0.006230625413557156\n",
      "Error of the epoch 918: 0.006229574193082912\n",
      "Error of the epoch 919: 0.006228525139962871\n",
      "Error of the epoch 920: 0.006227478248630345\n",
      "Error of the epoch 921: 0.0062264335135350755\n",
      "Error of the epoch 922: 0.006225390929143147\n",
      "Error of the epoch 923: 0.006224350489936937\n",
      "Error of the epoch 924: 0.006223312190415035\n",
      "Error of the epoch 925: 0.006222276025092185\n",
      "Error of the epoch 926: 0.006221241988499222\n",
      "Error of the epoch 927: 0.006220210075183002\n",
      "Error of the epoch 928: 0.006219180279706339\n",
      "Error of the epoch 929: 0.006218152596647947\n",
      "Error of the epoch 930: 0.006217127020602368\n",
      "Error of the epoch 931: 0.006216103546179914\n",
      "Error of the epoch 932: 0.006215082168006603\n",
      "Error of the epoch 933: 0.0062140628807240954\n",
      "Error of the epoch 934: 0.006213045678989633\n",
      "Error of the epoch 935: 0.006212030557475983\n",
      "Error of the epoch 936: 0.006211017510871366\n",
      "Error of the epoch 937: 0.006210006533879403\n",
      "Error of the epoch 938: 0.0062089976212190544\n",
      "Error of the epoch 939: 0.006207990767624556\n",
      "Error of the epoch 940: 0.006206985967845365\n",
      "Error of the epoch 941: 0.006205983216646096\n",
      "Error of the epoch 942: 0.006204982508806469\n",
      "Error of the epoch 943: 0.006203983839121239\n",
      "Error of the epoch 944: 0.006202987202400151\n",
      "Error of the epoch 945: 0.006201992593467874\n",
      "Error of the epoch 946: 0.006201000007163948\n",
      "Error of the epoch 947: 0.0062000094383427235\n",
      "Error of the epoch 948: 0.006199020881873313\n",
      "Error of the epoch 949: 0.00619803433263952\n",
      "Error of the epoch 950: 0.006197049785539798\n",
      "Error of the epoch 951: 0.0061960672354871875\n",
      "Error of the epoch 952: 0.006195086677409264\n",
      "Error of the epoch 953: 0.00619410810624808\n",
      "Error of the epoch 954: 0.006193131516960116\n",
      "Error of the epoch 955: 0.0061921569045162205\n",
      "Error of the epoch 956: 0.0061911842639015575\n",
      "Error of the epoch 957: 0.006190213590115559\n",
      "Error of the epoch 958: 0.006189244878171867\n",
      "Error of the epoch 959: 0.00618827812309828\n",
      "Error of the epoch 960: 0.006187313319936705\n",
      "Error of the epoch 961: 0.0061863504637431005\n",
      "Error of the epoch 962: 0.0061853895495874315\n",
      "Error of the epoch 963: 0.0061844305725536125\n",
      "Error of the epoch 964: 0.00618347352773946\n",
      "Error of the epoch 965: 0.006182518410256639\n",
      "Error of the epoch 966: 0.006181565215230618\n",
      "Error of the epoch 967: 0.0061806139378006095\n",
      "Error of the epoch 968: 0.006179664573119537\n",
      "Error of the epoch 969: 0.006178717116353967\n",
      "Error of the epoch 970: 0.006177771562684071\n",
      "Error of the epoch 971: 0.006176827907303576\n",
      "Error of the epoch 972: 0.006175886145419715\n",
      "Error of the epoch 973: 0.00617494627225318\n",
      "Error of the epoch 974: 0.0061740082830380695\n",
      "Error of the epoch 975: 0.00617307217302185\n",
      "Error of the epoch 976: 0.006172137937465303\n",
      "Error of the epoch 977: 0.006171205571642477\n",
      "Error of the epoch 978: 0.006170275070840648\n",
      "Error of the epoch 979: 0.0061693464303602666\n",
      "Error of the epoch 980: 0.0061684196455149155\n",
      "Error of the epoch 981: 0.006167494711631263\n",
      "Error of the epoch 982: 0.0061665716240490226\n",
      "Error of the epoch 983: 0.006165650378120897\n",
      "Error of the epoch 984: 0.006164730969212544\n",
      "Error of the epoch 985: 0.00616381339270253\n",
      "Error of the epoch 986: 0.00616289764398228\n",
      "Error of the epoch 987: 0.006161983718456046\n",
      "Error of the epoch 988: 0.006161071611540849\n",
      "Error of the epoch 989: 0.006160161318666446\n",
      "Error of the epoch 990: 0.006159252835275285\n",
      "Error of the epoch 991: 0.006158346156822458\n",
      "Error of the epoch 992: 0.006157441278775668\n",
      "Error of the epoch 993: 0.006156538196615174\n",
      "Error of the epoch 994: 0.006155636905833763\n",
      "Error of the epoch 995: 0.006154737401936698\n",
      "Error of the epoch 996: 0.00615383968044168\n",
      "Error of the epoch 997: 0.006152943736878812\n",
      "Error of the epoch 998: 0.006152049566790546\n",
      "Error of the epoch 999: 0.006151157165731658\n",
      "Error of the epoch 1000: 0.0061502665292691985\n",
      "Accuracy of our LLSR:98.6%\n"
     ]
    }
   ],
   "source": [
    "w_batch, b_batch = train_batch(X_train, Y_train, lr=2, lambdar=0.5, epochs=1000)\n",
    "_ = test_vectorized(X_test, Y_test, w_batch, b_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to compare: the speed. Try to run the same number of epochs (1000) with SGD, vectorized training, you can see it still takes a long time to run compared to the fully batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = train_vectorized(X_train, Y_train, epochs=1000)\n",
    "_ = test_vectorized(X_test, Y_test, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Version of Minibatch Gradient Descent\n",
    "\n",
    "Finally, we can do minibatch training, it is the same as batch training (the formula) but one iteration runs over a subset of the whole dataset at a time, and those subsets (minibatches) are shuffle before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_minibatch(X_train, Y_train, batch_size=256, lr=0.1, lambdar=0.0001, epochs=50):\n",
    "    \n",
    "    n = X_train.shape[0]\n",
    "    \n",
    "    # Xavier Initialization\n",
    "    np.random.seed(1234)\n",
    "    w = np.random.randn(1, n) * (np.sqrt(2. / (n + 1)))\n",
    "    b = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Split into minibatches \n",
    "        # CODE HERE\n",
    "        X_minibatches = np.array_split(X_train, batch_size, axis=1)\n",
    "        Y_minibatches = np.array_split(Y_train, batch_size, axis=1)\n",
    "        \n",
    "        # We shuffle the minibatches of X and Y in the same way\n",
    "        # CODE HERE\n",
    "        perm = np.random.permutation(len(X_minibatches))\n",
    "        \n",
    "        # Now we can do the training, we cannot vectorize over different minibatches\n",
    "        # They are like our \"epochs\"\n",
    "        for i in range(len(X_minibatches)): # CODE HERE\n",
    "            \n",
    "            # Extract a minibatch to do training\n",
    "            X_current = X_minibatches[perm[i]] # CODE HERE\n",
    "            Y_current = Y_minibatches[perm[i]] # CODE HERE\n",
    "            m = X_current.shape[1]\n",
    "            \n",
    "            z = np.dot(w, X_current) + b\n",
    "\n",
    "            o = 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "            C = np.sum((Y_current - o)**2)/(2*m)\n",
    "\n",
    "            R = np.sum(w**2)/(2*m)\n",
    "\n",
    "            # Calculate the loss \n",
    "            # CODE HERE\n",
    "            L = C + lambdar*R\n",
    "\n",
    "            # Backward pass and update the weights/bias\n",
    "            # CODE HERE\n",
    "            dCdZ = ((o - Y_train) * o * (1 - o))/(m)\n",
    "            dCdw = np.dot(dCdZ, X_current.T)\n",
    "            dRdw = w/m\n",
    "            dLdw = dCdw + lambdar*dRdw\n",
    "\n",
    "            dLdb = (np.sum((o - Y_current) * o * (1 - o)))/m\n",
    "\n",
    "            w -= lr*dLdw\n",
    "            b -= lr*dLdb\n",
    "\n",
    "            print(\"Error of the iteration {0}: {1}\".format(epoch * B + i + 1, L))\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minibatch Training for this LLSR is very sensitive to hyperparameter choosing. Should use with early stopping. Do not supprise if the accurary is bad. Shuffling the minibatch also takes time, so do not run this with large number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,784) and (1,4000) not aligned: 784 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e6382c983f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Do not run this for more than 100 epochs!!!!!!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw_minibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_minibatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_vectorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_minibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_minibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-f373cc5aa47a>\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(X_train, Y_train, batch_size, lr, lambdar, epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_current\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,784) and (1,4000) not aligned: 784 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Do not run this for more than 100 epochs!!!!!!!!!\n",
    "w_minibatch, b_minibatch = train_minibatch(X_train, Y_train, batch_size=512, lr=0.001, lambdar=0.0001, epochs=30)\n",
    "_ = test_vectorized(X_test, Y_test, w_minibatch, b_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
